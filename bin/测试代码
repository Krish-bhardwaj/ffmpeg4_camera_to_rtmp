#include "pch.h"
#include <iostream>
#include <time.h>
#include <winsock2.h>
#include <winsock.h>
//#include <sys/time.h>
//#include <sys/time.h>
using namespace std;
extern "C"
{
 
#include "libavformat/avformat.h"
#include "libavcodec/avcodec.h"
#include "libavdevice/avdevice.h"
#include "libavutil/imgutils.h"  
#include "libswscale/swscale.h"
#include "libavutil/timestamp.h"
#include "libavutil/rational.h"
 
	//引入时间
#include "libavutil/time.h"
}
void captureFrame()
{
	//输入文件
	AVInputFormat* ifmt = av_find_input_format("dshow");
	AVFormatContext* infmt_ctx = NULL;
	AVFormatContext* outfmt_ctx = NULL;
	if (0 > avformat_open_input(&infmt_ctx, "video=USB2.0 PC CAMERA", ifmt, NULL)) {
		printf("failed open input file\n");
		return;
	}
	if (0 > avformat_find_stream_info(infmt_ctx, NULL)) {
		printf("failed find stream info\n");
		avformat_close_input(&infmt_ctx);
		return;
	}
	int stream_index = -1;
	stream_index = av_find_best_stream(infmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);
	if (-1 == stream_index) {
		printf("failed find stream\n");
		avformat_close_input(&infmt_ctx);
		return;
	}
	//av_dump_format(infmt_ctx, 0, "video=USB2.0 PC CAMERA", 1);
	//END输入文件
 
	//编码器
	AVCodec* encodec = NULL;
	encodec = avcodec_find_encoder_by_name("libx264");
	if (!encodec) {
		printf("not find encoder\n");
		avformat_close_input(&infmt_ctx);
		return;
	}
	AVCodecContext* encodec_ctx = NULL;
	encodec_ctx = avcodec_alloc_context3(encodec);
	if (!encodec_ctx) {
		printf("not alloc context3\n\n");
		avformat_close_input(&infmt_ctx);
		return;
	}
	int num; ///< Numerator
	int den; ///< Denominator
	encodec_ctx->bit_rate = 400000;
	encodec_ctx->width = 340;
	encodec_ctx->height = 240;
	encodec_ctx->time_base.num = 1;
	encodec_ctx->time_base.den = 25;
	encodec_ctx->framerate.num = 25;
	encodec_ctx->framerate.den = 1;
	encodec_ctx->gop_size = 10;
	encodec_ctx->max_b_frames = 0;
	encodec_ctx->pix_fmt = AV_PIX_FMT_YUV420P;
 
	AVDictionary *param = NULL;
	av_dict_set(&param, "preset", "superfast", 0);
	av_dict_set(&param, "tune", "zerolatency", 0);
	av_dict_set(&param, "profile", "main", 0);
 
	if (0 > avcodec_open2(encodec_ctx, encodec, &param)) {
		printf("failed open coder\n");
		avformat_close_input(&infmt_ctx);
		return;
	}
 
	//END编码器
 
	//输出文件
	
	if (0 > avformat_alloc_output_context2(&outfmt_ctx, nullptr, "flv", "rtmp://localhost/testlive")) {
		printf("failed alloc output context\n");
		avformat_close_input(&infmt_ctx);
		return;
	}
 
	AVStream* out_stream = avformat_new_stream(outfmt_ctx, encodec_ctx->codec);
	if (!out_stream) {
		printf("failed new stream\n");
		avformat_close_input(&infmt_ctx);
		avformat_close_input(&outfmt_ctx);
		return;
	}
	avcodec_copy_context(out_stream->codec, encodec_ctx);
	//out_stream->codecpar->codec_tag = 0;
	if (0 > avio_open(&outfmt_ctx->pb, "rtmp://localhost/testlive", AVIO_FLAG_WRITE)) {
		printf("failed to open outfile\n");
		avformat_close_input(&infmt_ctx);
		avformat_close_input(&outfmt_ctx);
		return;
	}
 
	av_dump_format(outfmt_ctx, 0, "rtmp://localhost/testlive", 1);
 
	if (0 > avformat_write_header(outfmt_ctx, NULL)) {
		printf("failed to write header\n");
		avio_close(outfmt_ctx->pb);
		avformat_close_input(&infmt_ctx);
		avformat_close_input(&outfmt_ctx);
		return;
	}
	//END输出文件
	
 
	AVPacket packet;
	av_init_packet(&packet);
	packet.data = NULL;
	packet.size = 0;
 
	unsigned char *src_data[4];
	unsigned char *dst_data[4];
	int src_linesize[4];
	int dst_linesize[4];
 
	struct SwsContext *sws_ctx = sws_getContext(infmt_ctx->streams[stream_index]->codec->width, infmt_ctx->streams[stream_index]->codec->height,
		infmt_ctx->streams[stream_index]->codec->pix_fmt, 340, 240, AV_PIX_FMT_YUV420P,
		SWS_BILINEAR, NULL, NULL, NULL);
	int src_bufsize = av_image_alloc(src_data, src_linesize, infmt_ctx->streams[stream_index]->codec->width, infmt_ctx->streams[stream_index]->codec->height, infmt_ctx->streams[stream_index]->codec->pix_fmt, 16);
	int dst_bufsize = av_image_alloc(dst_data, dst_linesize, 340, 240, AV_PIX_FMT_YUV420P, 1);
 
	AVFrame* outFrame = av_frame_alloc();
	int picture_size = avpicture_get_size(encodec_ctx->pix_fmt,encodec_ctx->width, encodec_ctx->height);
	unsigned char* picture_buf = (uint8_t *)av_malloc(picture_size);
	avpicture_fill((AVPicture *)outFrame, picture_buf, encodec_ctx->pix_fmt, encodec_ctx->width, encodec_ctx->height);
	outFrame->format = encodec_ctx->pix_fmt;
	outFrame->width = encodec_ctx->width;
	outFrame->height = encodec_ctx->height;
 
	int y_size = encodec_ctx->width*encodec_ctx->height;
	AVPacket outpkt;
	av_new_packet(&outpkt, picture_size);
 
 
	int loop = 0;
	int got_picture = -1;
	int delayedFrame = 0;
	while (1) {
		av_read_frame(infmt_ctx, &packet);
		if (packet.stream_index == stream_index) {
 
			memcpy(src_data[0], packet.data, packet.size);
			sws_scale(sws_ctx, src_data, src_linesize, 0, infmt_ctx->streams[stream_index]->codec->height, dst_data, dst_linesize);
			outFrame->data[0] = dst_data[0];
			outFrame->data[1] = dst_data[0] + y_size;
			outFrame->data[2] = dst_data[0] + y_size * 5 / 4;
			outFrame->pts = loop;
			loop++;
			printf("encoding frame %3d---------", loop);
			avcodec_encode_video2(encodec_ctx, &outpkt, outFrame, &got_picture);
			if (1 == got_picture) {
				outpkt.stream_index = out_stream->index;
				av_interleaved_write_frame(outfmt_ctx, &outpkt);
				av_free_packet(&outpkt);
				printf("output frame %3d\n", loop - delayedFrame);
			}
			else {
				delayedFrame++;
				printf("no output frame\n");
			}
		}
		av_packet_unref(&packet);
	}
	av_write_trailer(outfmt_ctx);
	av_free(outFrame);
	av_free(picture_buf);
	avio_close(outfmt_ctx->pb);
	avformat_close_input(&infmt_ctx);
	avformat_close_input(&outfmt_ctx);
	return;
}
int main(void) {
	av_register_all();
	avformat_network_init();
	avcodec_register_all();
	avdevice_register_all();
	captureFrame();
	return 0;
}
————————————————
版权声明：本文为CSDN博主「雨夜和阳晨」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_42717961/article/details/85252234